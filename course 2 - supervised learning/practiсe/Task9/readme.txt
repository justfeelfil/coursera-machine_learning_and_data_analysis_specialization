¬ыбор семейства распределений в наивном байесе

¬ этом задании вы сможете немного расслабитьс€ после реализации случайного леса и градиентного бустинга по мотивам материалов прошлой недели. ¬се, что нужно будет делать Ч
запускать методы из sklearn. ¬ам предлагаетс€ вы€снить, какое распределение лучше использовать в наивном байесовском классификаторе в зависимости от вида признаков.

«агрузите датасеты digits и breast_cancer из sklearn.datasets. ¬ыведите несколько строчек из обучающих выборок и посмотрите на признаки. — помощью sklearn.cross_validation.cross_val_score
c настройками по умолчанию и вызова метода mean() у возвращаемого этой функцией numpy.ndarray, сравните качество работы наивных байесовских классификаторов на этих двух датасетах.
ƒл€ сравнени€ предлагаетс€ использовать BernoulliNB, MultinomialNB и GaussianNB. Ќасколько полученные результаты согласуютс€ с рекомендаци€ми из лекций?

ƒва датасета, конечно, еще не повод делать далеко идущие выводы, но при желании вы можете продолжить исследование на других выборках (например, из UCI репозитори€).